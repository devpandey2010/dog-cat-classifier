{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e3cf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0 21.8M    0  110k    0     0  37738      0  0:10:07  0:00:03  0:10:04 52793\n",
      "  2 21.8M    2  543k    0     0   142k      0  0:02:37  0:00:03  0:02:34  183k\n",
      "  6 21.8M    6 1454k    0     0   302k      0  0:01:14  0:00:04  0:01:10  367k\n",
      " 11 21.8M   11 2592k    0     0   449k      0  0:00:49  0:00:05  0:00:44  527k\n",
      " 24 21.8M   24 5472k    0     0   808k      0  0:00:27  0:00:06  0:00:21 1116k\n",
      " 41 21.8M   41 9296k    0     0  1196k      0  0:00:18  0:00:07  0:00:11 1927k\n",
      " 57 21.8M   57 12.6M    0     0  1463k      0  0:00:15  0:00:08  0:00:07 2461k\n",
      " 75 21.8M   75 16.4M    0     0  1721k      0  0:00:13  0:00:09  0:00:04 3101k\n",
      " 91 21.8M   91 20.0M    0     0  1911k      0  0:00:11  0:00:10  0:00:01 3596k\n",
      "100 21.8M  100 21.8M    0     0  1972k      0  0:00:11  0:00:11 --:--:-- 3690k\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "!curl -L -o cats-and-dogs-mini-dataset.zip\\\n",
    "https://www.kaggle.com/api/v1/datasets/download/aleemaparakatta/cats-and-dogs-mini-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4496a593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file data already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"cats-and-dogs-mini-dataset.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"dataset\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf2c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the 'data' directory if it doesn't exist\n",
    "data_dir = 'data'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Create the 'train' and 'test' subdirectories within 'data'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99563d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the source and destination paths\n",
    "source_cat = 'dataset/cats_set'\n",
    "dest_cat = 'dataset/cat'\n",
    "source_dog = 'dataset/dogs_set'\n",
    "dest_dog = 'dataset/dog'\n",
    "\n",
    "# Rename the directories if they exist\n",
    "if os.path.exists(source_cat):\n",
    "  os.rename(source_cat, dest_cat)\n",
    "\n",
    "if os.path.exists(source_dog):\n",
    "  os.rename(source_dog, dest_dog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2c4b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def train_test_split_folder(source_folder, train_folder, test_folder, split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Splits a folder of images into training and testing sets.\n",
    "\n",
    "    Args:\n",
    "        source_folder: Path to the source folder containing subfolders for each class.\n",
    "        train_folder: Path to the folder where the training set will be saved.\n",
    "        test_folder: Path to the folder where the testing set will be saved.\n",
    "        split_ratio: The ratio of images to include in the training set (default is 0.8).\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(train_folder):\n",
    "        os.makedirs(train_folder)\n",
    "    if not os.path.exists(test_folder):\n",
    "        os.makedirs(test_folder)\n",
    "\n",
    "    for class_name in os.listdir(source_folder):\n",
    "        class_source_path = os.path.join(source_folder, class_name)\n",
    "\n",
    "        if os.path.isdir(class_source_path):  # Check if it is a directory\n",
    "            train_class_path = os.path.join(train_folder, class_name)\n",
    "            test_class_path = os.path.join(test_folder, class_name)\n",
    "\n",
    "            if not os.path.exists(train_class_path):\n",
    "                os.makedirs(train_class_path)\n",
    "            if not os.path.exists(test_class_path):\n",
    "                os.makedirs(test_class_path)\n",
    "\n",
    "            images = [f for f in os.listdir(class_source_path) if os.path.isfile(os.path.join(class_source_path, f))]\n",
    "            random.shuffle(images)\n",
    "            split_index = int(len(images) * split_ratio)\n",
    "            train_images = images[:split_index]\n",
    "            test_images = images[split_index:]\n",
    "\n",
    "            for image in train_images:\n",
    "                source_path = os.path.join(class_source_path, image)\n",
    "                destination_path = os.path.join(train_class_path, image)\n",
    "                shutil.copy(source_path, destination_path)\n",
    "\n",
    "            for image in test_images:\n",
    "                source_path = os.path.join(class_source_path, image)\n",
    "                destination_path = os.path.join(test_class_path, image)\n",
    "                shutil.copy(source_path, destination_path)\n",
    "\n",
    "\n",
    "# Example usage (assuming you have your data organized in a 'data/train' folder):\n",
    "train_test_split_folder(\"dataset\", \"data/train\", \"data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3ba0246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: data\\test\\cat, Number of images: 100\n",
      "Folder: data\\test\\dog, Number of images: 100\n",
      "Folder: data\\train\\cat, Number of images: 400\n",
      "Folder: data\\train\\dog, Number of images: 400\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_images_per_folder(root_folder):\n",
    "  \"\"\"\n",
    "  Counts the number of images in each subfolder of a given root folder.\n",
    "\n",
    "  Args:\n",
    "    root_folder: The path to the root folder.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary where keys are folder paths and values are the number of images in each folder.\n",
    "  \"\"\"\n",
    "\n",
    "  image_counts = {}\n",
    "  for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "    image_count = 0\n",
    "    for filename in filenames:\n",
    "      if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "        image_count += 1\n",
    "    if image_count > 0 :\n",
    "      image_counts[dirpath] = image_count\n",
    "  return image_counts\n",
    "\n",
    "# Example usage\n",
    "image_counts = count_images_per_folder(\"data\")\n",
    "for folder, count in image_counts.items():\n",
    "    print(f\"Folder: {folder}, Number of images: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efdec5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder PATH listing for volume Windows \n",
      "Volume serial number is 84AF-5727\n",
      "C:\\USERS\\BIT\\ONEDRIVE\\DESKTOP\\DOG-CAT CLASSIFIER\\DATA\n",
      "+---test\n",
      "�   +---cat\n",
      "�   +---dog\n",
      "+---train\n",
      "    +---cat\n",
      "    +---dog\n"
     ]
    }
   ],
   "source": [
    "!tree data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c2cd1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "805745fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61ba7ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to train and test folders\n",
    "train_dir = \"data/train\"\n",
    "test_dir = \"data/test\"\n",
    "image_size = (128, 128)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "846d7b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 640 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "test_data = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c7cdab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 63, 63, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               3211392   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3304769 (12.61 MB)\n",
      "Trainable params: 3304769 (12.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # binary classification\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f0e333c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\BIT\\OneDrive\\Desktop\\Dog-cat classifier\\.venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\BIT\\OneDrive\\Desktop\\Dog-cat classifier\\.venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "20/20 [==============================] - 17s 755ms/step - loss: 0.7074 - accuracy: 0.5078 - val_loss: 0.6900 - val_accuracy: 0.6500\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 7s 342ms/step - loss: 0.6915 - accuracy: 0.5312 - val_loss: 0.6867 - val_accuracy: 0.5250\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 7s 358ms/step - loss: 0.6821 - accuracy: 0.5437 - val_loss: 0.6793 - val_accuracy: 0.7000\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 7s 341ms/step - loss: 0.6789 - accuracy: 0.5688 - val_loss: 0.6751 - val_accuracy: 0.5750\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 7s 326ms/step - loss: 0.6672 - accuracy: 0.6359 - val_loss: 0.6616 - val_accuracy: 0.7000\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 7s 322ms/step - loss: 0.6566 - accuracy: 0.6281 - val_loss: 0.6493 - val_accuracy: 0.6000\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 7s 329ms/step - loss: 0.6365 - accuracy: 0.6328 - val_loss: 0.6473 - val_accuracy: 0.7000\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 7s 325ms/step - loss: 0.6206 - accuracy: 0.6484 - val_loss: 0.6293 - val_accuracy: 0.7000\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 7s 342ms/step - loss: 0.5987 - accuracy: 0.6891 - val_loss: 0.6106 - val_accuracy: 0.7250\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 7s 342ms/step - loss: 0.5671 - accuracy: 0.7437 - val_loss: 0.5995 - val_accuracy: 0.7250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25882033750>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the Model\n",
    "checkpoint_path = 'dog_cat_cnn_model.keras'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "model.fit(\n",
    "    train_data,\n",
    "    epochs=10,\n",
    "    validation_data=test_data,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2cad7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "model.save('dog_cat_final_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84eb2d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the best saved model\n",
    "model = load_model('dog_cat_final_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32955948",
   "metadata": {},
   "source": [
    "MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b68f5e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 2 classes.\n",
      "2/2 [==============================] - 1s 137ms/step - loss: 0.6208 - accuracy: 0.6600\n",
      "Validation Accuracy: 66.00%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#set parameters\n",
    "val_dir=test_dir #same directory used for training\n",
    "image_size=(128,128)\n",
    "batch_size=32\n",
    "\n",
    "#recreate the validation generator\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.25)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "# Evaluate model accuracy\n",
    "loss, accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea6d09b",
   "metadata": {},
   "source": [
    "MODELINFERENCING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "def predict_image(img_path,model):\n",
    "    img=image.load_img(img_path,target_size=(128,128))\n",
    "    img_array=image.img_to_array(img)/255.0\n",
    "    img_array=np.expand_dims(img_array,axis=0)\n",
    "\n",
    "    prediction=model.predict(img_array)[0][0]\n",
    "\n",
    "    if prediction >0.5:\n",
    "        print(\"predictied:Dog\")\n",
    "    else:\n",
    "        print(\"predicted:Cat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23f8e45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n",
      "predictied:Dog\n"
     ]
    }
   ],
   "source": [
    "predict_image(\"data/train/dog/dog.4156.jpg\", model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
