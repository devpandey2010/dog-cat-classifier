{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76e3cf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0 21.8M    0 14949    0     0   8700      0  0:43:56  0:00:01  0:43:55  8700\n",
      "  0 21.8M    0  149k    0     0  75348      0  0:05:04  0:00:02  0:05:02  428k\n",
      "  9 21.8M    9 2160k    0     0   716k      0  0:00:31  0:00:03  0:00:28 1655k\n",
      " 25 21.8M   25 5613k    0     0  1398k      0  0:00:16  0:00:04  0:00:12 2437k\n",
      " 41 21.8M   41 9373k    0     0  1869k      0  0:00:11  0:00:05  0:00:06 2839k\n",
      " 58 21.8M   58 12.7M    0     0  2176k      0  0:00:10  0:00:06  0:00:04 3042k\n",
      " 74 21.8M   74 16.2M    0     0  2378k      0  0:00:09  0:00:07  0:00:02 3319k\n",
      " 91 21.8M   91 19.9M    0     0  2551k      0  0:00:08  0:00:08 --:--:-- 3657k\n",
      "100 21.8M  100 21.8M    0     0  2624k      0  0:00:08  0:00:08 --:--:-- 3713k\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "!curl -L -o cats-and-dogs-mini-dataset.zip\\\n",
    "https://www.kaggle.com/api/v1/datasets/download/aleemaparakatta/cats-and-dogs-mini-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4496a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"cats-and-dogs-mini-dataset.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"dataset\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acf2c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the 'data' directory if it doesn't exist\n",
    "data_dir = 'data'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Create the 'train' and 'test' subdirectories within 'data'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99563d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the source and destination paths\n",
    "source_cat = 'dataset/cats_set'\n",
    "dest_cat = 'dataset/cat'\n",
    "source_dog = 'dataset/dogs_set'\n",
    "dest_dog = 'dataset/dog'\n",
    "\n",
    "# Rename the directories if they exist\n",
    "if os.path.exists(source_cat):\n",
    "  os.rename(source_cat, dest_cat)\n",
    "\n",
    "if os.path.exists(source_dog):\n",
    "  os.rename(source_dog, dest_dog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2c4b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def train_test_split_folder(source_folder, train_folder, test_folder, split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Splits a folder of images into training and testing sets.\n",
    "\n",
    "    Args:\n",
    "        source_folder: Path to the source folder containing subfolders for each class.\n",
    "        train_folder: Path to the folder where the training set will be saved.\n",
    "        test_folder: Path to the folder where the testing set will be saved.\n",
    "        split_ratio: The ratio of images to include in the training set (default is 0.8).\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(train_folder):\n",
    "        os.makedirs(train_folder)\n",
    "    if not os.path.exists(test_folder):\n",
    "        os.makedirs(test_folder)\n",
    "\n",
    "    for class_name in os.listdir(source_folder):\n",
    "        class_source_path = os.path.join(source_folder, class_name)\n",
    "\n",
    "        if os.path.isdir(class_source_path):  # Check if it is a directory\n",
    "            train_class_path = os.path.join(train_folder, class_name)\n",
    "            test_class_path = os.path.join(test_folder, class_name)\n",
    "\n",
    "            if not os.path.exists(train_class_path):\n",
    "                os.makedirs(train_class_path)\n",
    "            if not os.path.exists(test_class_path):\n",
    "                os.makedirs(test_class_path)\n",
    "\n",
    "            images = [f for f in os.listdir(class_source_path) if os.path.isfile(os.path.join(class_source_path, f))]\n",
    "            random.shuffle(images)\n",
    "            split_index = int(len(images) * split_ratio)\n",
    "            train_images = images[:split_index]\n",
    "            test_images = images[split_index:]\n",
    "\n",
    "            for image in train_images:\n",
    "                source_path = os.path.join(class_source_path, image)\n",
    "                destination_path = os.path.join(train_class_path, image)\n",
    "                shutil.copy(source_path, destination_path)\n",
    "\n",
    "            for image in test_images:\n",
    "                source_path = os.path.join(class_source_path, image)\n",
    "                destination_path = os.path.join(test_class_path, image)\n",
    "                shutil.copy(source_path, destination_path)\n",
    "\n",
    "\n",
    "# Example usage (assuming you have your data organized in a 'data/train' folder):\n",
    "train_test_split_folder(\"dataset\", \"data/train\", \"data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3ba0246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: data\\test\\cat, Number of images: 100\n",
      "Folder: data\\test\\dog, Number of images: 100\n",
      "Folder: data\\train\\cat, Number of images: 400\n",
      "Folder: data\\train\\dog, Number of images: 400\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_images_per_folder(root_folder):\n",
    "  \"\"\"\n",
    "  Counts the number of images in each subfolder of a given root folder.\n",
    "\n",
    "  Args:\n",
    "    root_folder: The path to the root folder.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary where keys are folder paths and values are the number of images in each folder.\n",
    "  \"\"\"\n",
    "\n",
    "  image_counts = {}\n",
    "  for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "    image_count = 0\n",
    "    for filename in filenames:\n",
    "      if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "        image_count += 1\n",
    "    if image_count > 0 :\n",
    "      image_counts[dirpath] = image_count\n",
    "  return image_counts\n",
    "\n",
    "# Example usage\n",
    "image_counts = count_images_per_folder(\"data\")\n",
    "for folder, count in image_counts.items():\n",
    "    print(f\"Folder: {folder}, Number of images: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efdec5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder PATH listing for volume Windows \n",
      "Volume serial number is 84AF-5727\n",
      "C:\\USERS\\BIT\\ONEDRIVE\\DESKTOP\\DOG-CAT CLASSIFIER\\DATA\n",
      "+---test\n",
      "�   +---cat\n",
      "�   +---dog\n",
      "+---train\n",
      "    +---cat\n",
      "    +---dog\n"
     ]
    }
   ],
   "source": [
    "!tree data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c2cd1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "805745fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61ba7ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to train and test folders\n",
    "train_dir = \"data/train\"\n",
    "test_dir = \"data/test\"\n",
    "image_size = (128, 128)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "846d7b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 640 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "test_data = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c7cdab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 63, 63, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               3211392   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3304769 (12.61 MB)\n",
      "Trainable params: 3304769 (12.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # binary classification\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f0e333c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.5172WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001807D06F920> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "20/20 [==============================] - 15s 636ms/step - loss: 0.6930 - accuracy: 0.5172 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BIT\\OneDrive\\Desktop\\Dog-cat classifier\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 14s 701ms/step - loss: 0.6920 - accuracy: 0.4984 - val_loss: 0.6926 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 15s 725ms/step - loss: 0.6874 - accuracy: 0.5656 - val_loss: 0.6907 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 14s 687ms/step - loss: 0.6798 - accuracy: 0.5844 - val_loss: 0.6898 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 13s 622ms/step - loss: 0.6674 - accuracy: 0.5984 - val_loss: 0.6882 - val_accuracy: 0.5750\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 15s 771ms/step - loss: 0.6664 - accuracy: 0.6062 - val_loss: 0.6907 - val_accuracy: 0.6000\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 15s 733ms/step - loss: 0.6513 - accuracy: 0.6422 - val_loss: 0.6837 - val_accuracy: 0.5500\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 14s 725ms/step - loss: 0.6300 - accuracy: 0.6828 - val_loss: 0.6570 - val_accuracy: 0.6250\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 15s 752ms/step - loss: 0.6082 - accuracy: 0.6687 - val_loss: 0.6450 - val_accuracy: 0.5500\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 16s 793ms/step - loss: 0.5935 - accuracy: 0.7000 - val_loss: 0.6300 - val_accuracy: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1807d698550>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the Model\n",
    "checkpoint_path = 'dog_cat_cnn_model.keras.h5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "model.fit(\n",
    "    train_data,\n",
    "    epochs=10,\n",
    "    validation_data=test_data,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2cad7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "model.save('dog_cat_final_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84eb2d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the best saved model\n",
    "model = load_model('dog_cat_final_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32955948",
   "metadata": {},
   "source": [
    "MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b68f5e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 143ms/step - loss: 0.6258 - accuracy: 0.6200\n",
      "Validation Accuracy: 62.00%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#set parameters\n",
    "val_dir=test_dir #same directory used for training\n",
    "image_size=(128,128)\n",
    "batch_size=32\n",
    "\n",
    "#recreate the validation generator\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.25)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "# Evaluate model accuracy\n",
    "loss, accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea6d09b",
   "metadata": {},
   "source": [
    "MODELINFERENCING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3f5fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "def predict_image(img_path,model):\n",
    "    img=image.load_img(img_path,target_size=(128,128))\n",
    "    img_array=image.img_to_array(img)/255.0\n",
    "    img_array=np.expand_dims(img_array,axis=0)\n",
    "\n",
    "    prediction=model.predict(img_array)[0][0]\n",
    "\n",
    "    if prediction >0.5:\n",
    "        print(\"predictied:Dog\")\n",
    "    else:\n",
    "        print(\"predicted:Cat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23f8e45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 187ms/step\n",
      "predictied:Dog\n"
     ]
    }
   ],
   "source": [
    "predict_image(\"data/train/dog/dog.4156.jpg\", model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
